---
title: ""
---

# Introduction

The purpose of this course is to teach you the basics of the Python language and give you the confidence to tackle larger projects using the language. *Importantly, we want to get you thinking like a programmer*. This doesn't mean that by the end of the course you will know Python fully, but you will know *enough* so you can go online and look for the help you need to complete most tasks.

## Practice makes perfect

Programming is like any skill, the more you practice the better you get. ***It's really important that you keep using what you have learned after the course is completed*** otherwise there is a good chance you will forget everything and you'll be back to square one.

## Why use Python?

Python is a high-level **general** programming language (unlike R which has a focus on mathematics and statistics) so Python can be used for a wide variety of applications. When it comes to machine learning, Python seems to have the edge and is preferred by the data scientist community for it;s AI/ML capabilitioes. In bioinformatics we see Python making real in-roads as more packages become available. One of the most popular ones being [Scanpy](https://scanpy.readthedocs.io/en/stable/) and the [scverse](https://scverse.org) which handle single-cell analysis Python is free and available for all operating systems. 

## Which other languages do bioinformaticians use?

[R](https://cran.r-project.org) of course which has a long rich history in boinformatics, and most will have heard of [Bioconductor](https://www.bioconductor.org) which is a collection of packages to anaylse biological and genomics data. For very computationally intensive tasks (e.g sequence alignment), languages such as C/C++/Rust are more commonly used, but these are far more difficult to learn.

## How will this course work?

We're going to take a different approach to this course. You will be taught the basics of the Python language while doing small exercises along the way. However, we will finish by you undertaking a project which will push you quite hard. The aim is that by tacking a more difficult problem will consolidate what you have learnt, and learn more by having to look up solutions to the problems you will likely face.

## Getting Python

Python is slightly different in that we make "environments" on our computers and work within these environment which makes them self-contained. You need to install Miniconda, so go [here](https://www.anaconda.com/docs/getting-started/miniconda/main) and follow the instructions to install Miniconda on your system.

When you have installed Miniconda, we need to make an environment and install Python and some other packages that we need to get going. On your computer, open a terminal and do:

```
conda create -n workshop.env python=3.10
```
And when this is done, activate the enviroment by doing:
```
conda activate workshop.env
```

You are now inside the `workshop.env` environment. Anything you install/do here, will stay here.

Lets install some packages that we'll need:

```
conda install -c conda-forge jupyterlab notebook nbclient ipykernel pandas matplotlib numpy
```

We also need to register this environment as a Jupyter kernel we will use to run commands:

```
python -m ipykernel install --user --name quarto-env --display-name "Python (quarto-env)"
```

## Choosing an editor

Ask a hundred different programmer which editor is best, and you will get a hundred different answers. These are the two which people tend to recommend the most when asked:

1. [VScode](https://code.visualstudio.com). This is a general purpose editor which is really popular. It will handle pretty much all languages, and plugins will make it easier to write and run code. This is the one I use, and the one we#ll use fo this course.

2. [PyCharm](https://www.jetbrains.com/pycharm/). This is a Python specific editor which has a rediculous number of features. You can play with this in your own time!

# The basics

Lets start gently and go through a few simple things to warm up.

## Assigning a variable.

Into your script copy/type the following line:

```{python}
x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
```

This will make a **vector** of values from 1 to 10, and put them into a variable called `x`.

Execute the code by hitting the "Run" button at the top-right of the script window. You will see this line appear in the R console below.

To view the contents of the object you have just created, just type `x` in the **console** and hit return:

```{python}
x
```

The contents of x are now printed out.

**Now is a good time to learn about commenting and documenting code**. This is free text you put into your scripts that tell the reader whats going on. It also helps remind your future self of what you did or your thought process. Comments are put in using `#`, so for example:

```{python}
x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] # This is a comment
```

Anything after a `#` will be ignored by Python. You can run the code again to check.

Rather than typing in the value 1 to 10, there is a much simpler way to create the same vector using `:`

```{python}
x = list(range(1,11))
print(x)
```

Much better! It's also bidirectional, so to go backwards it's:

```{python}
y = list(range(5, -6, -1))
y
```

Issue the command `help(range)`. In python you can get a manual for any function using the `help()` command. Look at the help page and generate a vector of numbers from 1 to 100 in steps of 10:

```{python}
a = list(range(0, 101,10))
a
```

Lets try something a bit more difficult. Generate a vector called `b` ranging from 3 to 987 where the length of the vector is 53 entries long. Done? Check the length of the vector you have just made.

In Python, there is a greater reliance on packages for working with numbers, and the package which we will use the most is `numpy`. To load a package we do:

```{python}
import numpy
```

The way we use functions from a package is by doing `numpy.X` where `.X` is replaced by the name of the function in the `numpy` package you need. You can already see that if you need to use `numpy` functions a lot, then having to type `numpy` all the time is going to be a drag. So what we can do here is shorted it by doing:

```{python}
import numpy as np
```

So now, if you want to use a `numpy` function we just use `np.X`

```{python}
b = np.arange(3, 938, 53)  # 938 is exclusive, so it matches R's inclusive 937
length = len(b)
print(length)
```

We can also make a new vector `d` using a vector `c`:

```{python}
c = np.arange(1, 51)  # 1 to 50 inclusive
d = 1 / c
print(d)
```

And do maths on them, for example calculate the mean of `d`:

```{python}
mean_d = np.mean(d)
print(mean_d)
```

```{python}
std_d = np.std(d)
print(std_d)
```

## Conditionals

This is important stuff. If we want to ask whether something is equal to something else, we need to use the `==` operator, NOT `=`. Try this:

```{python}
x = np.arange(1,11)
x == 5
```

We can also do some other simple but important things:

```{python}
print(np.where(x < 5))
print(np.where(x <= 5))
print(np.where(x >= 5))
print(np.where(x > 5))
print(np.where(x != 5))
```

Lets make another vector `y`:

```{python}
y = np.arange(7,16)
common = np.intersect1d(x, y)
print(common)
```

What do you think this does?

```{python}
result = x[~np.isin(x, y)]
print(result)
```

## Basic plotting

In order to plot, we need another module called `matplotlib`, specifically, a submodule called `pyplot` which can be thought of as base plotting in R (if you use R). Lets load it:

```{python}
import matplotlib.pyplot as plt
```

To plot we do:

```{python}
plt.plot(d)
```

Do some googling and see how you can add a title, label the x/y axis, make the line points instead, and colour them red.

Here is how I would do it:

```{python}
plt.plot(c,d, marker='o',color="red")
plt.title("c")
plt.xlabel("Index")
plt.ylabel("d")
plt.show()
```

We can make this plot a little fancier. Those who work in R will be familiar with `ggplot2` package, and there is a direct port to that in Python called `plotnine`. We use this in combaination with `pandas` which is the module that creates and handles data.frames (more on this later):

```{python}
from plotnine import ggplot, aes, geom_line, geom_point
import pandas as pd

df = pd.DataFrame({'col1': c, 'col2': d})

# Plot
p = (
    ggplot(df, aes(x='col1', y='col2')) +
    geom_line(color='red') +
    geom_point(color='green')
)
p.draw()
```

If you want to do it the "pure" Python way (and we probably should!) we can to the following using `seaborn` plus `matplotlib`:

```{python}

import seaborn as sns

df = pd.DataFrame({'col1': c, 'col2': d})

# Plot
plt.figure(figsize=(8, 5))
sns.lineplot(data=df, x='col1', y='col2', color='red')   # red line
sns.scatterplot(data=df, x='col1', y='col2', color='green')  # green points

plt.title("1/c vs c")
plt.xlabel("col1")
plt.ylabel("col2")
plt.show()
```

Lets have a look at the manual for pandas. Go [here](https://pandas.pydata.org/docs/index.html). This modules has extensive documentation, and at the top you can clokc on "API" which will list out all the methods which can be used on a `pandas` DataFrame.


# Matricies

Matrices are the most common data format bioinformaticians work with. Microarray/RNAseq/single-cell data are all kept in matricies where gene are in the rows and samples down in the columns. Lets make a simple matrix of zeros using `numpy`:

```{python}
m = np.zeros((10, 5))  # 10 rows, 5 columns
print(m)
```

This will create a matrix filled with zeros. To transpose (flip) the matrix we use t() (this will be important later!)

```{python}
tposed_m = m.T
print(tposed_m)
```

We usually need to name the rows and columns (genes/samples), so for that we need to switch to using a pandas dataframe because np matricies do not take labels:

```{python}
df = pd.DataFrame(
    m,
    index=["A","B","C","D","E","F","G","H","I","J"],
    columns=["cat", "dog", "pig", "cow", "chicken"]
)
print(df)
```

## Subsetting

Lets make a matrix (and a vector) containing integer values so we can take a look at how subsetting work in R:


```{python}
#m = np.arange(1, 51).reshape((5, 10), order='F').T  # 10x5 after transpose
v = np.arange(1, 11)

m = np.arange(1, 51).reshape((10, 5))

df = pd.DataFrame(
    m,
    index=["A","B","C","D","E","F","G","H","I","J"],
    columns=["cat", "dog", "pig", "cow", "chicken"]
)
print(df)
```

We can access individual elements using square brackets `[]`. So to get the 6th, 1st and 5th elements of `v` we need:

```{python}
print(v[[6,0,4]])
```

Why? Because **Python counts from 0.** If you have been using R until now, you will know it is one based. To get the first element of a vector in R you would d `v[1]`, but this isn't so in Python. In fact, pretty much all languages are 0 based. Wit this in mind, lets look ar the first row of the matrix `m`.

```{python}
print(df.iloc[0,:])
```

and the 3rd column:

```{python}
print(df.iloc[:,2])
```


```{python}
print(df.iloc[:,[1,4]]) # the 2nd and 5th column
```

```{python}
print(df.iloc[:,[1,4]]) 
```


```{python}
print(df.iloc[2:7, 3]) # the 3rd to 7th row of the 4th column. Remember 7 is exclusive
```


```{python}
print(df.loc["B",:]) # gets the row labelled B
```


```{python}
print(df.loc["B","cow"])
```


```{python}
print(df.loc[["F", "J"],["chicken", "cat", "pig"]])
```

We often need to collect vectors and assemble them into a matrix. This can be done using the rbind (row) and cbind (column) functions:

```{python}
v1 = np.arange(1, 11)         # [1, 2, ..., 10]
v2 = np.arange(101, 111)      # [101, 102, ..., 110]

rbound_mat = np.vstack([v1, v2])
print(rbound_mat)
```


# Dictionaries
So far we have talked about vectors and matrices separately, but we often we want to collect these things and put them into one object under a single variable as a collection (for example expression data and gene annotation). To do this we use something called a **dictionary**. 


```{python}
alpha = ["A", "B", "C", "D", "E", "F", "G", "H"]
mat = np.random.randn(8, 5)  # 8 rows, 5 columns of random normal values

listex1 = {
    "char": alpha,
    "nums": mat
}
```

You can see that each item is given a name `char` `nums` before it is put into the list. Each element can now be accessed via `[]`:

```{python}
listex1["char"]
```

So to access the 3rd element of the vector:

```{python}
listex1["char"][2]
```

And the first row of the dataframe:

```{python}
listex1["nums"][0,:]
```

```{python}
from sklearn.datasets import load_iris
iris_data = load_iris(as_frame=True)
iris = iris_data.frame  # pandas DataFrame

# Sample 10 random rows
iris.head(5)
#type(iris)
```

```{python}
plt.scatter(iris["sepal length (cm)"], iris["sepal width (cm)"])
plt.xlabel("Sepal Length")
plt.ylabel("Sepal Width")
plt.title("Sepal Length vs Sepal Width")
plt.show()
```


```{python}
iris["species"] = iris_data.target_names[iris_data.target]

# Create the plot

sns.scatterplot(data=iris, x="sepal length (cm)", y="sepal width (cm)", hue="species")

# Display the plot
plt.title("Sepal Length vs Sepal Width")
plt.show()
```


We can also break up a data frame up on attributes and store the contents in a list (which we have already discussed). For example by species:

```{python}

iris_sp = {species: data for species, data in iris.groupby("species")}

# Show the keys (species names) of the dictionary
list(iris_sp.keys())
```


```{python}
iris_sp['setosa'].iloc[0:3, :3]

```

```{python}
iris_sp['versicolor'].iloc[0:3, :3]
```


Let do some basic filtering and manipulation of this data. First, filter just for those which are setosa:
```{python}
setosa_data = iris[iris["species"] == "setosa"]
setosa_data.iloc[:5]
```

Select 3 specific columsn of the data

```{python}
iris_subset = iris[["sepal length (cm)", "sepal width (cm)", "species"]]
iris_subset.iloc[:5]
```

Sort on a field:

```{python}
iris_sorted = iris.sort_values("sepal length (cm)")
iris_sorted.head(10)
```


# Reading and writing files

You have to get the data into R first before you can analyse it (this helps a lot). R has many useful functions to do this, so now we can take our first look at some expression data. Download this [file](https://github.com/sccbioinformatics/Python_programming_1/blob/main/Mouse_HSPC_reduced.txt) and save it to your current working directory.

***Exercise***: Open the file in Excel or something to see how it looks. As we want a **named** matrix we know that we want a `pandas` dataframe. So call `help(pd.read_csv)` in the terminal and try to work out how to import this file.

This is how I would do it:

```{python}
#| code-fold: true
hspc_data = pd.read_csv("Mouse_HSPC_reduced.txt", sep="\t", header=0, index_col=0)
```


Lets look are the first few lines:

```{python}
hspc_data.head(5)
```

Lets have a look at the dimensions of the data. In the `pandas` module we have the `shape` function to get this:

```{python}
hspc_data.shape
```

We can access the individal components of this using:

```{python}
hspc_data.shape[0]
```

```{python}
hspc_data.shape[1]
```

Lets take a look at the column names and see what they look like:

```{python}
list(hspc_data.columns)
```

It's quite common that we need to break a table up. In this case, we want to separate the different populations into dataframes called `lthsc`,`mep`, and `gmp`.

To do this we need to get to the string atributes of the column headers, and to do this we need to use `.str` and the functions contained within. an example of this:

```{python}
mep_data = hspc_data.loc[:, hspc_data.columns.str.contains("MEP")]
```

Let break this down inside out. `hspc_data.columns.str.contains("MEP")` accessing the string functions using `.str`, and then uses the `.contains` function to ask which of the `.columns` contains "MEP". We then pass the results of this to `hspc_data.loc` to pull out the corresponsing columns.

Lets run the inner part by itself:

```{python}
hspc_data.columns.str.contains("MEP")
```

We can also get the same results by using `.startswith` instead:

```{python}
hspc_data.columns.str.startswith("MEP")
```

***Exercise***: Isolate the data for the LTHSC and GMP data into objects called `lthsc_data` and `gmp_data`.

```{python}
#| code-fold: true
lthsc_data = hspc_data.loc[:, hspc_data.columns.str.contains("LTHSC")]
gmp_data = hspc_data.loc[:, hspc_data.columns.str.contains("GMP")]
```

Let have a look at another important task, writing out a file.

***Exercise***: Call `pd.DataFrame.to_csv` and have a look at the help page. Try and figure out how to write the `lthsc_data` to a file called `LTHSC_data.txt`.


```{python}
#| code-fold: true
lthsc_data.to_csv("LTHSC_data.txt", sep="\t", index=True, header=True)
```

***Exercise***: Write out the other two files!

```{python}
#| code-fold: true
mep_data.to_csv("MEP_data.txt", sep="\t", index=True, header=True)
gmp_data.to_csv("GMP_data.txt", sep="\t", index=True, header=True)
```

# Flow control basics

This is where things get more interesting and we start to feel like "proper" programmers. Now that we have these datasets loaded in Python, we can use them to learn about flow control and some basic mathematical functions. We are going to do a few things the “long way” so you get the idea of how flow control works, and then we’ll look at some shortcuts.

Flow control is how multi-step processes (such as algorithms) are carried out. In the example below we print out the numbers 1 to 10:

```{python}
for i in range(10):
    print(i)
```

To translate this code, it simply says for every integer from 0 to 9, print this value to the screen.

***Exercises***:

1. Using the example above, print the first 10 lines of 'lthcs_data' in a for loop.


```{python}
#| code-fold: true
#| eval: false
for i in range(10):
    print(hspc_data.iloc[i,:])
```

2. Print every 2nd line of `mep_data` from lines 0 to 49.

```{python}
#| code-fold: true
#| eval: false
for i in range(0,50,2):
    print(hspc_data.iloc[i,:])
```


An important point regarding for loops is that any processes/calculations occurring within the loop will stay in the loop. If data generated within a loop has to be retained, we need to create a container to “fill up” while the loop is being carried out. for example:

```{python}
vec = []

for i in range(10):
    vec.append(i * 10)

print(vec)
```

The empty container `vec` is initialised outside the loop, and then populated by concatenating to it using `append` after every iteration of the loop.

***Exercise***: Initialise an empty container, and for `gmp_data`, calculate the mean of each row (gene), and store the results in the container you made.


```{python}
gmp_row_means = []
for i in range(gmp_data.shape[0]):
    gmp_row_means.append(gmp_data.iloc[i,:].mean())
print(len(gmp_row_means))
```

Another method of flow control is `while`. for example:

```{python}
w = 0
while (w <= 5):
    print(w)
    w = w + 1
```

We will cover `if` and `else` a bit later.

# Functions

Functions are chunks of code that execute several lines of code at once to perform a task. Once you have a few lines of useful code that you want to apply repeatedly, a function is a nice way to wrap them up so it can be used quickly when needed. Lets turn the code you wrote in the previous exercise into a function where we also calculate the variance for a gene.

```{python}
def calc_mean_and_var(mat):
    means = []
    variances = []
    
    for i in range(mat.shape[0]):
        row = mat.iloc[i, :]
        means.append(np.mean(row))
        variances.append(np.var(row))

    return {"mns": means, "vars": variances} # This line gives us back what we need.
```

Here, you can see a loop is started, and the output from each loop is appended to containers `means` and `variances`. These are both put into a list which is returned at the end. By putting this code into a function we can now calculate the means and deviations of any matrix in one line of code. For example, the `gmp` data:

```{python}
gmp_mn_var = calc_mean_and_var(gmp_data)
print(gmp_mn_var["mns"])
print(gmp_mn_var["vars"])
```
